{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15846251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of URL Matching:\n",
      "- Total organizations: 166\n",
      "- Organizations with URLs: 91\n",
      "- Match rate: 54.8%\n",
      "Updated JSON created successfully\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Load JSON data\n",
    "region = 'nijmegen'\n",
    "json_file = f'zorginstellingen-{region}.json'\n",
    "updated_json_file = f'zorginstellingen-{region}-updated.json'\n",
    "# Check if the file exists  and is not empty\n",
    "try:\n",
    "    with open(json_file, 'r', encoding='utf-8') as f:\n",
    "        json_data = json.load(f)\n",
    "except FileNotFoundError:\n",
    "    print(f\"File {json_file} not found. Please check the file path.\")\n",
    "    exit(1)\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"File {json_file} is empty or not a valid JSON file.\")\n",
    "    exit(1)\n",
    "\n",
    "# Load XLSX data using pandas\n",
    "# This replaces the CSV reading code\n",
    "excel_data = pd.read_excel('openbaar-databestand-kwaliteitsbeeld-generiek-kompas-verslagjaar-2024.xlsx')\n",
    "csv_data = excel_data.to_dict('records')\n",
    "\n",
    "# Create a map of organization names to URLs from the Excel data\n",
    "org_to_url_map = {}\n",
    "\n",
    "for row in csv_data:\n",
    "    if (row.get('IndicatorNaam') == \"Wat is de URL van de publieke website waar het Kwaliteitsbeeld van uw zorgorganisatie te vinden is?\" and \n",
    "        row.get('IndicatorWaarde') and \n",
    "        isinstance(row.get('IndicatorWaarde'), str)):\n",
    "        \n",
    "        url = row.get('IndicatorWaarde').strip()\n",
    "        \n",
    "        # Clean up URLs that might not be properly formatted\n",
    "        if url.startswith('chrome-extension://'):\n",
    "            # Extract the actual URL after the chrome-extension part\n",
    "            matches = re.search(r'https?://[^\\s]+', url)\n",
    "            if matches:\n",
    "                url = matches.group(0)\n",
    "        elif url.startswith('www'):\n",
    "            # Add https:// to URLs that start with www\n",
    "            url = 'https://' + url\n",
    "        \n",
    "        # Store the organization name and URL\n",
    "        if url:\n",
    "            org_to_url_map[row.get('OrganisatieNaam')] = url\n",
    "\n",
    "# Create a lookup function\n",
    "def find_best_match(json_org_name, csv_org_names):\n",
    "    # Clean up the name to handle common variations\n",
    "    def clean_name(name):\n",
    "        return name.lower().replace(' ', ' ').replace(',', '').strip()\n",
    "    \n",
    "    clean_json_name = clean_name(json_org_name)\n",
    "    \n",
    "    # First try for exact matches (after cleaning)\n",
    "    for csv_name in csv_org_names:\n",
    "        if clean_name(csv_name) == clean_json_name:\n",
    "            return csv_name\n",
    "    \n",
    "    # If no exact match, try partial matches\n",
    "    # First, try to match the main organization name\n",
    "    # Many JSON entries have format \"OrgName, location X\" or \"OrgName, X\"\n",
    "    main_org_name = clean_json_name.split(',')[0].strip()\n",
    "    \n",
    "    for csv_name in csv_org_names:\n",
    "        clean_csv_name = clean_name(csv_name)\n",
    "        if clean_csv_name == main_org_name or main_org_name == clean_csv_name:\n",
    "            return csv_name\n",
    "    \n",
    "    # If still no match, try more flexible matching\n",
    "    for csv_name in csv_org_names:\n",
    "        clean_csv_name = clean_name(csv_name)\n",
    "        if clean_csv_name in main_org_name or main_org_name in clean_csv_name:\n",
    "            return csv_name\n",
    "    \n",
    "    # No match found\n",
    "    return None\n",
    "\n",
    "# Get all CSV organization names\n",
    "csv_org_names = list(org_to_url_map.keys())\n",
    "\n",
    "# Now update the JSON data with URLs\n",
    "updated_json_data = []\n",
    "for item in json_data:\n",
    "    # Add a new field for the URL\n",
    "    new_item = item.copy()\n",
    "    new_item['KwaliteitsbeeldURL'] = \"\"\n",
    "    \n",
    "    # Try to find a match\n",
    "    matched_org_name = find_best_match(item['Naam'], csv_org_names)\n",
    "    if matched_org_name and matched_org_name in org_to_url_map:\n",
    "        new_item['KwaliteitsbeeldURL'] = org_to_url_map[matched_org_name]\n",
    "    \n",
    "    updated_json_data.append(new_item)\n",
    "\n",
    "# Count how many URLs we were able to add\n",
    "urls_added = sum(1 for item in updated_json_data if item['KwaliteitsbeeldURL'])\n",
    "match_rate = (urls_added / len(updated_json_data)) * 100\n",
    "\n",
    "print(f\"Summary of URL Matching:\")\n",
    "print(f\"- Total organizations: {len(updated_json_data)}\")\n",
    "print(f\"- Organizations with URLs: {urls_added}\")\n",
    "print(f\"- Match rate: {match_rate:.1f}%\")\n",
    "\n",
    "# Save the updated JSON\n",
    "with open(updated_json_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(updated_json_data, f, indent=2)\n",
    "\n",
    "print(\"Updated JSON created successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
